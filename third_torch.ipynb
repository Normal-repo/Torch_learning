{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "DByQKhyP2YNs",
        "outputId": "a8ffb9bb-6289-43a1-920e-eb75d70a9e33"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0    842302         M        17.99         10.38          122.80     1001.0   \n",
              "1    842517         M        20.57         17.77          132.90     1326.0   \n",
              "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
              "3  84348301         M        11.42         20.38           77.58      386.1   \n",
              "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
              "\n",
              "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0          0.11840           0.27760          0.3001              0.14710   \n",
              "1          0.08474           0.07864          0.0869              0.07017   \n",
              "2          0.10960           0.15990          0.1974              0.12790   \n",
              "3          0.14250           0.28390          0.2414              0.10520   \n",
              "4          0.10030           0.13280          0.1980              0.10430   \n",
              "\n",
              "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
              "0  ...          17.33           184.60      2019.0            0.1622   \n",
              "1  ...          23.41           158.80      1956.0            0.1238   \n",
              "2  ...          25.53           152.50      1709.0            0.1444   \n",
              "3  ...          26.50            98.87       567.7            0.2098   \n",
              "4  ...          16.67           152.20      1575.0            0.1374   \n",
              "\n",
              "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
              "0             0.6656           0.7119                0.2654          0.4601   \n",
              "1             0.1866           0.2416                0.1860          0.2750   \n",
              "2             0.4245           0.4504                0.2430          0.3613   \n",
              "3             0.8663           0.6869                0.2575          0.6638   \n",
              "4             0.2050           0.4000                0.1625          0.2364   \n",
              "\n",
              "   fractal_dimension_worst  Unnamed: 32  \n",
              "0                  0.11890          NaN  \n",
              "1                  0.08902          NaN  \n",
              "2                  0.08758          NaN  \n",
              "3                  0.17300          NaN  \n",
              "4                  0.07678          NaN  \n",
              "\n",
              "[5 rows x 33 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-58cc4399-3807-451e-8e29-b5e792cb47e9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 33 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58cc4399-3807-451e-8e29-b5e792cb47e9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-58cc4399-3807-451e-8e29-b5e792cb47e9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-58cc4399-3807-451e-8e29-b5e792cb47e9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/master/data.csv\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "HQXTUb0h3cHn"
      },
      "outputs": [],
      "source": [
        "df.drop(columns=['id','Unnamed: 32'],inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"diagnosis\"].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isMZHTPhNrL6",
        "outputId": "406679cc-3c26-41bc-81be-3df868dfd4fe"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['M', 'B'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "xkm7agnX23zx"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, 1:], df.iloc[:, 0], test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "tX3s0eKw4adG"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "BfiaW5rn4ddz"
      },
      "outputs": [],
      "source": [
        "encoder = LabelEncoder()\n",
        "y_train = encoder.fit_transform(y_train)\n",
        "y_test = encoder.transform(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "T60uuYiI4mn6"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "2MyZEYyH0AsV"
      },
      "outputs": [],
      "source": [
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "eHsa9hdr6Dz0"
      },
      "outputs": [],
      "source": [
        "X_train_tensor = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test_tensor = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train_tensor = torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test_tensor = torch.from_numpy(y_test.astype(np.float32))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset,DataLoader"
      ],
      "metadata": {
        "id": "gNyaiaENJiRv"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.features.shape[0]   # number of samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.labels[idx]\n",
        "\n"
      ],
      "metadata": {
        "id": "bVyynjjVJoxX"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset=CustomDataset(X_train_tensor,y_train_tensor)\n",
        "test_dataset=CustomDataset(X_test_tensor,y_test_tensor)"
      ],
      "metadata": {
        "id": "DZw64aWEKCBZ"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "2iQAxTerKnHQ"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class mysimplenn(nn.Module):\n",
        "  def __init__(self,num_features) -> None:\n",
        "      super().__init__()\n",
        "      self.linear=nn.Linear(num_features,128)\n",
        "      self.relu=nn.ReLU()\n",
        "      self.linear2=nn.Linear(128,1)\n",
        "      self.sigmoid=nn.Sigmoid()\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=self.linear(x)\n",
        "    x=self.relu(x)\n",
        "    x=self.linear2(x)\n",
        "    x=self.sigmoid(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "Ze7P-G--Ls-z"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.1\n",
        "epochs = 250"
      ],
      "metadata": {
        "id": "7zTWCSTpPJPf"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=mysimplenn(X_train_tensor.shape[1])"
      ],
      "metadata": {
        "id": "DKbX64RrPK8b"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fINZBJkwQf2v",
        "outputId": "11e66c66-ae36-4440-daee-aebaddd5fa65"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([455, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optim=torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
        "loss_function=nn.BCELoss()"
      ],
      "metadata": {
        "id": "cXuahdWcPPRf"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  for x,y in train_loader:\n",
        "    y_pred=model(x)\n",
        "\n",
        "    loss=loss_function(y_pred,y.view(-1,1))\n",
        "\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "  print(f'epoch: {epoch}, loss: {loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhTKdScgPdmE",
        "outputId": "72c74d1d-9dd9-4f7a-b4ce-97b3cc329d90"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, loss: 0.4011630415916443\n",
            "epoch: 1, loss: 0.47278666496276855\n",
            "epoch: 2, loss: 0.03150957077741623\n",
            "epoch: 3, loss: 0.05399923399090767\n",
            "epoch: 4, loss: 0.03614341467618942\n",
            "epoch: 5, loss: 0.06973905861377716\n",
            "epoch: 6, loss: 0.07954501360654831\n",
            "epoch: 7, loss: 0.005141128320246935\n",
            "epoch: 8, loss: 0.01371213048696518\n",
            "epoch: 9, loss: 0.046037767082452774\n",
            "epoch: 10, loss: 0.3309773802757263\n",
            "epoch: 11, loss: 0.014411481097340584\n",
            "epoch: 12, loss: 0.020135624334216118\n",
            "epoch: 13, loss: 0.011136299930512905\n",
            "epoch: 14, loss: 0.03883155435323715\n",
            "epoch: 15, loss: 0.017095239832997322\n",
            "epoch: 16, loss: 0.08243941515684128\n",
            "epoch: 17, loss: 0.35649770498275757\n",
            "epoch: 18, loss: 0.02535095252096653\n",
            "epoch: 19, loss: 0.023116962984204292\n",
            "epoch: 20, loss: 0.05126947909593582\n",
            "epoch: 21, loss: 0.0159135852009058\n",
            "epoch: 22, loss: 0.03287065774202347\n",
            "epoch: 23, loss: 0.011643079109489918\n",
            "epoch: 24, loss: 0.08565778285264969\n",
            "epoch: 25, loss: 0.07640542089939117\n",
            "epoch: 26, loss: 0.038953494280576706\n",
            "epoch: 27, loss: 0.026330947875976562\n",
            "epoch: 28, loss: 0.002308241557329893\n",
            "epoch: 29, loss: 0.11763779819011688\n",
            "epoch: 30, loss: 0.03224889561533928\n",
            "epoch: 31, loss: 0.06493709981441498\n",
            "epoch: 32, loss: 0.007343236356973648\n",
            "epoch: 33, loss: 0.12631957232952118\n",
            "epoch: 34, loss: 0.0005464956047944725\n",
            "epoch: 35, loss: 0.02121669426560402\n",
            "epoch: 36, loss: 0.0017797277541831136\n",
            "epoch: 37, loss: 0.15589220821857452\n",
            "epoch: 38, loss: 0.0169521477073431\n",
            "epoch: 39, loss: 0.04178736358880997\n",
            "epoch: 40, loss: 0.05247821658849716\n",
            "epoch: 41, loss: 0.012943423353135586\n",
            "epoch: 42, loss: 0.019186705350875854\n",
            "epoch: 43, loss: 0.003976941574364901\n",
            "epoch: 44, loss: 0.020509686321020126\n",
            "epoch: 45, loss: 0.004226748365908861\n",
            "epoch: 46, loss: 0.008414543233811855\n",
            "epoch: 47, loss: 0.014136764220893383\n",
            "epoch: 48, loss: 0.0016076702158898115\n",
            "epoch: 49, loss: 0.02830473892390728\n",
            "epoch: 50, loss: 0.03634084016084671\n",
            "epoch: 51, loss: 0.002095790347084403\n",
            "epoch: 52, loss: 0.028227610513567924\n",
            "epoch: 53, loss: 0.04384667053818703\n",
            "epoch: 54, loss: 0.012921561487019062\n",
            "epoch: 55, loss: 0.0006521851755678654\n",
            "epoch: 56, loss: 0.07520236819982529\n",
            "epoch: 57, loss: 0.0050473702140152454\n",
            "epoch: 58, loss: 0.0002460413670632988\n",
            "epoch: 59, loss: 0.030090318992733955\n",
            "epoch: 60, loss: 0.007401357404887676\n",
            "epoch: 61, loss: 0.002756438683718443\n",
            "epoch: 62, loss: 0.33213871717453003\n",
            "epoch: 63, loss: 0.0005457131774164736\n",
            "epoch: 64, loss: 0.2919985353946686\n",
            "epoch: 65, loss: 0.13647662103176117\n",
            "epoch: 66, loss: 0.07573385536670685\n",
            "epoch: 67, loss: 0.02929040417075157\n",
            "epoch: 68, loss: 0.026861706748604774\n",
            "epoch: 69, loss: 0.05463637039065361\n",
            "epoch: 70, loss: 0.2609077990055084\n",
            "epoch: 71, loss: 0.24519911408424377\n",
            "epoch: 72, loss: 0.03431626409292221\n",
            "epoch: 73, loss: 0.0718388706445694\n",
            "epoch: 74, loss: 0.22465237975120544\n",
            "epoch: 75, loss: 0.1016545444726944\n",
            "epoch: 76, loss: 0.023935815319418907\n",
            "epoch: 77, loss: 0.024314777925610542\n",
            "epoch: 78, loss: 0.00019434068235568702\n",
            "epoch: 79, loss: 0.02171260118484497\n",
            "epoch: 80, loss: 0.01182322483509779\n",
            "epoch: 81, loss: 0.0020514552015811205\n",
            "epoch: 82, loss: 0.007721459027379751\n",
            "epoch: 83, loss: 0.1943744421005249\n",
            "epoch: 84, loss: 0.017567317932844162\n",
            "epoch: 85, loss: 0.005275117699056864\n",
            "epoch: 86, loss: 0.1989448070526123\n",
            "epoch: 87, loss: 0.01758405938744545\n",
            "epoch: 88, loss: 0.02688831277191639\n",
            "epoch: 89, loss: 0.012365594506263733\n",
            "epoch: 90, loss: 0.0016939553897827864\n",
            "epoch: 91, loss: 0.023194553330540657\n",
            "epoch: 92, loss: 0.06095728650689125\n",
            "epoch: 93, loss: 0.011353743262588978\n",
            "epoch: 94, loss: 0.0069187399931252\n",
            "epoch: 95, loss: 0.007124289870262146\n",
            "epoch: 96, loss: 0.02030552737414837\n",
            "epoch: 97, loss: 0.011849318630993366\n",
            "epoch: 98, loss: 0.01572888158261776\n",
            "epoch: 99, loss: 0.0024189376272261143\n",
            "epoch: 100, loss: 0.00033573180553503335\n",
            "epoch: 101, loss: 0.01136175636202097\n",
            "epoch: 102, loss: 0.029270457103848457\n",
            "epoch: 103, loss: 0.001001702039502561\n",
            "epoch: 104, loss: 0.019516468048095703\n",
            "epoch: 105, loss: 0.0005838783108629286\n",
            "epoch: 106, loss: 0.003324272111058235\n",
            "epoch: 107, loss: 4.684602390625514e-05\n",
            "epoch: 108, loss: 0.0022630621679127216\n",
            "epoch: 109, loss: 0.09319291263818741\n",
            "epoch: 110, loss: 0.012699355371296406\n",
            "epoch: 111, loss: 0.0002778404741548002\n",
            "epoch: 112, loss: 0.000427326129283756\n",
            "epoch: 113, loss: 0.006857449654489756\n",
            "epoch: 114, loss: 0.016194503754377365\n",
            "epoch: 115, loss: 0.0055418601259589195\n",
            "epoch: 116, loss: 0.0004936277982778847\n",
            "epoch: 117, loss: 0.01280526164919138\n",
            "epoch: 118, loss: 0.08093426376581192\n",
            "epoch: 119, loss: 0.009593845345079899\n",
            "epoch: 120, loss: 0.01270853728055954\n",
            "epoch: 121, loss: 0.01132357306778431\n",
            "epoch: 122, loss: 0.001860605669207871\n",
            "epoch: 123, loss: 0.006235633511096239\n",
            "epoch: 124, loss: 0.00024612806737422943\n",
            "epoch: 125, loss: 0.011813848279416561\n",
            "epoch: 126, loss: 0.0034214723855257034\n",
            "epoch: 127, loss: 4.3193536839680746e-05\n",
            "epoch: 128, loss: 0.013904663734138012\n",
            "epoch: 129, loss: 0.00039838277734816074\n",
            "epoch: 130, loss: 0.006467257160693407\n",
            "epoch: 131, loss: 0.009304574690759182\n",
            "epoch: 132, loss: 0.009598487056791782\n",
            "epoch: 133, loss: 0.015569322742521763\n",
            "epoch: 134, loss: 0.07467050105333328\n",
            "epoch: 135, loss: 0.032667942345142365\n",
            "epoch: 136, loss: 0.0075063747353851795\n",
            "epoch: 137, loss: 0.008755075745284557\n",
            "epoch: 138, loss: 0.009878578595817089\n",
            "epoch: 139, loss: 0.0025725180748850107\n",
            "epoch: 140, loss: 0.004991550464183092\n",
            "epoch: 141, loss: 2.679849785636179e-05\n",
            "epoch: 142, loss: 0.002068138448521495\n",
            "epoch: 143, loss: 0.1544302999973297\n",
            "epoch: 144, loss: 0.2520163953304291\n",
            "epoch: 145, loss: 0.0024714861065149307\n",
            "epoch: 146, loss: 0.000648990913759917\n",
            "epoch: 147, loss: 0.005759790539741516\n",
            "epoch: 148, loss: 0.008092260919511318\n",
            "epoch: 149, loss: 0.005896301474422216\n",
            "epoch: 150, loss: 0.00047857314348220825\n",
            "epoch: 151, loss: 0.0018890092615038157\n",
            "epoch: 152, loss: 0.03243504837155342\n",
            "epoch: 153, loss: 0.007315585855394602\n",
            "epoch: 154, loss: 0.0016361279413104057\n",
            "epoch: 155, loss: 0.009809649549424648\n",
            "epoch: 156, loss: 0.009711978957057\n",
            "epoch: 157, loss: 0.011003056541085243\n",
            "epoch: 158, loss: 0.0076436796225607395\n",
            "epoch: 159, loss: 0.004579641856253147\n",
            "epoch: 160, loss: 0.029022103175520897\n",
            "epoch: 161, loss: 0.00016808595682960004\n",
            "epoch: 162, loss: 0.031784020364284515\n",
            "epoch: 163, loss: 0.00011411953892093152\n",
            "epoch: 164, loss: 0.0005401931703090668\n",
            "epoch: 165, loss: 0.008052169345319271\n",
            "epoch: 166, loss: 0.007352903019636869\n",
            "epoch: 167, loss: 0.0002498288231436163\n",
            "epoch: 168, loss: 0.010277480818331242\n",
            "epoch: 169, loss: 0.00798318162560463\n",
            "epoch: 170, loss: 0.000435384368756786\n",
            "epoch: 171, loss: 0.0012061202432960272\n",
            "epoch: 172, loss: 0.0003597794275265187\n",
            "epoch: 173, loss: 0.002207284327596426\n",
            "epoch: 174, loss: 0.002000580308958888\n",
            "epoch: 175, loss: 0.0005731710116378963\n",
            "epoch: 176, loss: 0.011586184613406658\n",
            "epoch: 177, loss: 0.0014175791293382645\n",
            "epoch: 178, loss: 0.006732538342475891\n",
            "epoch: 179, loss: 1.5328301742556505e-05\n",
            "epoch: 180, loss: 0.0016648572636768222\n",
            "epoch: 181, loss: 0.00012584462820086628\n",
            "epoch: 182, loss: 0.0013339583529159427\n",
            "epoch: 183, loss: 0.004261392634361982\n",
            "epoch: 184, loss: 1.2476679103201604e-06\n",
            "epoch: 185, loss: 0.023939311504364014\n",
            "epoch: 186, loss: 9.025838517118245e-05\n",
            "epoch: 187, loss: 0.00690921675413847\n",
            "epoch: 188, loss: 0.005172572564333677\n",
            "epoch: 189, loss: 0.0003876990231219679\n",
            "epoch: 190, loss: 0.018465397879481316\n",
            "epoch: 191, loss: 0.012050733901560307\n",
            "epoch: 192, loss: 0.0886903628706932\n",
            "epoch: 193, loss: 0.0017645928310230374\n",
            "epoch: 194, loss: 0.04986352473497391\n",
            "epoch: 195, loss: 0.001501143560744822\n",
            "epoch: 196, loss: 0.010975271463394165\n",
            "epoch: 197, loss: 0.015558125451207161\n",
            "epoch: 198, loss: 0.0024577791336923838\n",
            "epoch: 199, loss: 0.00017730046238284558\n",
            "epoch: 200, loss: 0.030814779922366142\n",
            "epoch: 201, loss: 0.002691825618967414\n",
            "epoch: 202, loss: 0.027848126366734505\n",
            "epoch: 203, loss: 0.02962818741798401\n",
            "epoch: 204, loss: 7.543279934907332e-05\n",
            "epoch: 205, loss: 0.012715274468064308\n",
            "epoch: 206, loss: 0.0014647325733676553\n",
            "epoch: 207, loss: 0.017317619174718857\n",
            "epoch: 208, loss: 0.0071807443164289\n",
            "epoch: 209, loss: 0.0004263741138856858\n",
            "epoch: 210, loss: 0.0011283013736829162\n",
            "epoch: 211, loss: 0.00021950030350126326\n",
            "epoch: 212, loss: 6.001305882818997e-05\n",
            "epoch: 213, loss: 0.00026852558949030936\n",
            "epoch: 214, loss: 0.010704045183956623\n",
            "epoch: 215, loss: 0.0005158241256140172\n",
            "epoch: 216, loss: 0.0010607604635879397\n",
            "epoch: 217, loss: 0.0013605438871309161\n",
            "epoch: 218, loss: 0.010347021743655205\n",
            "epoch: 219, loss: 0.03409416601061821\n",
            "epoch: 220, loss: 0.002207960234954953\n",
            "epoch: 221, loss: 0.003854986047372222\n",
            "epoch: 222, loss: 0.001804448664188385\n",
            "epoch: 223, loss: 0.0017229097429662943\n",
            "epoch: 224, loss: 0.0010400775354355574\n",
            "epoch: 225, loss: 0.0015318611403927207\n",
            "epoch: 226, loss: 0.09362754970788956\n",
            "epoch: 227, loss: 0.0012651144061237574\n",
            "epoch: 228, loss: 0.00542557192966342\n",
            "epoch: 229, loss: 0.007186858914792538\n",
            "epoch: 230, loss: 0.0013300961581990123\n",
            "epoch: 231, loss: 1.4845434634480625e-05\n",
            "epoch: 232, loss: 0.025021731853485107\n",
            "epoch: 233, loss: 0.0005792165175080299\n",
            "epoch: 234, loss: 0.0003540758043527603\n",
            "epoch: 235, loss: 0.0014624588657170534\n",
            "epoch: 236, loss: 0.0067908125929534435\n",
            "epoch: 237, loss: 0.000517454871442169\n",
            "epoch: 238, loss: 0.02851220965385437\n",
            "epoch: 239, loss: 0.0015902029117569327\n",
            "epoch: 240, loss: 0.09690345078706741\n",
            "epoch: 241, loss: 0.00032743875635787845\n",
            "epoch: 242, loss: 0.005862074438482523\n",
            "epoch: 243, loss: 0.0012601475464180112\n",
            "epoch: 244, loss: 0.003206646302714944\n",
            "epoch: 245, loss: 0.004815266001969576\n",
            "epoch: 246, loss: 0.0189705528318882\n",
            "epoch: 247, loss: 0.012704632245004177\n",
            "epoch: 248, loss: 0.009452919475734234\n",
            "epoch: 249, loss: 0.003533508162945509\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "accuracy_list=[]\n",
        "\n",
        "with torch.no_grad():\n",
        "  for x,y in test_loader:\n",
        "    y_pred=model(x)\n",
        "    y_pred = (y_pred > 0.8).float()\n",
        "    batch_accuracy = (y_pred.view(-1) == y).float().mean().item()\n",
        "    accuracy_list.append(batch_accuracy)\n",
        "\n",
        "overall_accuracy = sum(accuracy_list) / len(accuracy_list)\n",
        "print(f'Accuracy: {overall_accuracy:.4f}')\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxkjkGebRAmo",
        "outputId": "5d248721-45e8-4f5c-ac4a-86954843e7ec"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0000\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}